{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed scene 0063\n",
      "Processed scene 0051\n",
      "Processed scene 0228\n",
      "Processed scene 0275\n",
      "Processed scene 0041\n",
      "Processed scene 0022\n",
      "Processed scene 0199\n",
      "Processed scene 0271\n",
      "Processed scene 0152\n",
      "Processed scene 0113\n",
      "Processed scene 0014\n",
      "Processed scene 0054\n",
      "Processed scene 0052\n",
      "Processed scene 0064\n",
      "Processed scene 0053\n",
      "Processed scene 0082\n",
      "Processed scene 0240\n",
      "Processed scene 0176\n",
      "Processed scene 0097\n",
      "Processed scene 0069\n",
      "Processed scene 0191\n",
      "Processed scene 0159\n",
      "Processed scene 0232\n",
      "Processed scene 0150\n",
      "Processed scene 0104\n",
      "Processed scene 0083\n",
      "Processed scene 0246\n",
      "Processed scene 0025\n",
      "Processed scene 0230\n",
      "Processed scene 0248\n",
      "Processed scene 0024\n",
      "Processed scene 0143\n",
      "Processed scene 0149\n",
      "Processed scene 0231\n",
      "Processed scene 0220\n",
      "Processed scene 0103\n",
      "Processed scene 0233\n",
      "Processed scene 0283\n",
      "Processed scene 0267\n",
      "Processed scene 0288\n",
      "Processed scene 0045\n",
      "Processed scene 0100\n",
      "Processed scene 0004\n",
      "Processed scene 0135\n",
      "Processed scene 0209\n",
      "Processed scene 0081\n",
      "Processed scene 0251\n",
      "Processed scene 0273\n",
      "Processed scene 0098\n",
      "Processed scene 0194\n",
      "Processed scene 0256\n",
      "Processed scene 0074\n",
      "Processed scene 0105\n",
      "Processed scene 0144\n",
      "Processed scene 0153\n",
      "Processed scene 0075\n",
      "Processed scene 0260\n",
      "Processed scene 0033\n",
      "Processed scene 0161\n",
      "Processed scene 0236\n",
      "Processed scene 0287\n",
      "Processed scene 0026\n",
      "Processed scene 0203\n",
      "Processed scene 0034\n",
      "Processed scene 0158\n",
      "Processed scene 0013\n",
      "Processed scene 0058\n",
      "Processed scene 0132\n",
      "Processed scene 0120\n",
      "Processed scene 0166\n",
      "Processed scene 0259\n",
      "Processed scene 0263\n",
      "Processed scene 0090\n",
      "Processed scene 0016\n",
      "Processed scene 0087\n",
      "Processed scene 0145\n",
      "Processed scene 0020\n",
      "Processed scene 0290\n",
      "Processed scene 0235\n",
      "Processed scene 0070\n",
      "Processed scene 0002\n",
      "Processed scene 0179\n",
      "Processed scene 0108\n",
      "Processed scene 0241\n",
      "Processed scene 0009\n",
      "Processed scene 0091\n",
      "Processed scene 0222\n",
      "Processed scene 0102\n",
      "Processed scene 0021\n",
      "Processed scene 0109\n",
      "Processed scene 0155\n",
      "Processed scene 0293\n",
      "Processed scene 0285\n",
      "Processed scene 0095\n",
      "Processed scene 0079\n",
      "Processed scene 0119\n",
      "Processed scene 0133\n",
      "Processed scene 0130\n",
      "Processed scene 0141\n",
      "Processed scene 0234\n",
      "Processed scene 0188\n",
      "Processed scene 0101\n",
      "Processed scene 0123\n",
      "Processed scene 0112\n",
      "Processed scene 0272\n",
      "Processed scene 0080\n",
      "Processed scene 0001\n",
      "Processed scene 0127\n",
      "Processed scene 0279\n",
      "Processed scene 0015\n",
      "Processed scene 0226\n",
      "Processed scene 0061\n",
      "Processed scene 0136\n",
      "Processed scene 0254\n",
      "Processed scene 0202\n",
      "Processed scene 0110\n",
      "Processed scene 0189\n",
      "Processed scene 0086\n",
      "Processed scene 0167\n",
      "Processed scene 0046\n",
      "Processed scene 0174\n",
      "Processed scene 0011\n",
      "Processed scene 0237\n",
      "Processed scene 0289\n",
      "Processed scene 0128\n",
      "Processed scene 0040\n",
      "Processed scene 0115\n",
      "Processed scene 0172\n",
      "Processed scene 0225\n",
      "Processed scene 0276\n",
      "Processed scene 0085\n",
      "Processed scene 0266\n",
      "Processed scene 0208\n",
      "Processed scene 0089\n",
      "Processed scene 0280\n",
      "Processed scene 0116\n",
      "Processed scene 0006\n",
      "Processed scene 0060\n",
      "Processed scene 0270\n",
      "Processed scene 0219\n",
      "Processed scene 0243\n",
      "Processed scene 0137\n",
      "Processed scene 0023\n",
      "Processed scene 0031\n",
      "Processed scene 0099\n",
      "Processed scene 0140\n",
      "Processed scene 0129\n",
      "Processed scene 0012\n",
      "Processed scene 0093\n",
      "Processed scene 0000\n",
      "Processed scene 0261\n",
      "Processed scene 0156\n",
      "Processed scene 0092\n",
      "Processed scene 0216\n",
      "Processed scene 0269\n",
      "Processed scene 0286\n",
      "Processed scene 0050\n",
      "Processed scene 0217\n",
      "Processed scene 0170\n",
      "Processed scene 0072\n",
      "Processed scene 0138\n",
      "Processed scene 0177\n",
      "Processed scene 0073\n",
      "Processed scene 0169\n",
      "Processed scene 0148\n",
      "Processed scene 0096\n",
      "Processed scene 0106\n",
      "Processed scene 0201\n",
      "Processed scene 0162\n",
      "Processed scene 0147\n",
      "Processed scene 0017\n",
      "Processed scene 0175\n",
      "Processed scene 0253\n",
      "Processed scene 0265\n",
      "Processed scene 0173\n",
      "Processed scene 0190\n",
      "Processed scene 0142\n",
      "Processed scene 0139\n",
      "Processed scene 0032\n",
      "Processed scene 0039\n",
      "Processed scene 0207\n",
      "Processed scene 0154\n",
      "Processed scene 0077\n",
      "Processed scene 0067\n",
      "Processed scene 0218\n",
      "Processed scene 0282\n",
      "Processed scene 0038\n",
      "Processed scene 0062\n",
      "Processed scene 0126\n",
      "Processed scene 0047\n",
      "Processed scene 0198\n",
      "Processed scene 0088\n",
      "Processed scene 0214\n",
      "Processed scene 0212\n",
      "Processed scene 0178\n",
      "Processed scene 0200\n",
      "Processed scene 0003\n",
      "Processed scene 0107\n",
      "Processed scene 0244\n",
      "Processed scene 0035\n",
      "Processed scene 0049\n",
      "Processed scene 0018\n",
      "Processed scene 0195\n",
      "Processed scene 0151\n",
      "Processed scene 0277\n",
      "Processed scene 0257\n",
      "Processed scene 0029\n",
      "Processed scene 0163\n",
      "Processed scene 0030\n",
      "Processed scene 0146\n",
      "Processed scene 0262\n",
      "Processed scene 0160\n",
      "Processed scene 0281\n",
      "Processed scene 0027\n",
      "Processed scene 0084\n",
      "Processed scene 0118\n",
      "Processed scene 0249\n",
      "Processed scene 0057\n",
      "Processed scene 0264\n",
      "Processed scene 0068\n",
      "Processed scene 0007\n",
      "Processed scene 0227\n",
      "Processed scene 0037\n",
      "Processed scene 0180\n",
      "Processed scene 0205\n",
      "Processed scene 0008\n",
      "Processed scene 0043\n",
      "Processed scene 0121\n",
      "Processed scene 0124\n",
      "Processed scene 0114\n",
      "Processed scene 0164\n",
      "Processed scene 0278\n",
      "Processed scene 0196\n",
      "Processed scene 0213\n",
      "Processed scene 0299\n",
      "Processed scene 0185\n",
      "Processed scene 0252\n",
      "Processed scene 0131\n",
      "Processed scene 0298\n",
      "Processed scene 0183\n",
      "Processed scene 0125\n",
      "Processed scene 0122\n",
      "Processed scene 0134\n",
      "Processed scene 0028\n",
      "Processed scene 0117\n",
      "Processed scene 0274\n",
      "Processed scene 0165\n",
      "Processed scene 0211\n",
      "Processed scene 0258\n",
      "Processed scene 0221\n",
      "All scenes processed.\n",
      "Unique classes:\n",
      "0: Regular Table\n",
      "1: Regular Chair\n",
      "\n",
      "Unique parts:\n",
      "0: chair_decoration\n",
      "1: chair_back\n",
      "2: chair_leg\n",
      "3: chair_seat\n",
      "4: tabletop_surface\n",
      "5: table_base\n",
      "6: table_shelf\n",
      "7: other_tabletop\n",
      "8: wheel\n",
      "9: chair_arm\n",
      "10: pillow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "def process_point_clouds(dataset_dir, save_dir):\n",
    "    \"\"\"\n",
    "    Process point clouds, create masks, and generate summary files for each scene.\n",
    "    \n",
    "    Args:\n",
    "    dataset_dir (str): Path to the dataset directory.\n",
    "    save_dir (str): Path to save the processed results.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Dictionaries of unique classes and parts (cls_dict, part_dict).\n",
    "    \"\"\"\n",
    "    scene_dir = os.path.join(dataset_dir, 'part_valid')\n",
    "    gt_instance_dir = os.path.join(dataset_dir, 'mask_valid_gt')\n",
    "    id2cls_dir = os.path.join(dataset_dir,'id2ins_valid_gt')\n",
    "    id2part_dir = os.path.join(dataset_dir,'id2part_valid_gt')\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    cls_dict = {}\n",
    "    part_dict = {}\n",
    "    cls_index = 0\n",
    "    part_index = 0\n",
    "\n",
    "    for scene_id in os.listdir(scene_dir)[:50]:\n",
    "        # Create a directory for each scene\n",
    "        scene_save_dir = os.path.join(save_dir, scene_id)\n",
    "        os.makedirs(scene_save_dir, exist_ok=True)\n",
    "        \n",
    "        # Create pred_mask directory within the scene directory\n",
    "        pred_mask_dir = os.path.join(scene_save_dir, 'pred_mask')\n",
    "        os.makedirs(pred_mask_dir, exist_ok=True)\n",
    "\n",
    "        # Load JSON files\n",
    "        with open(os.path.join(id2cls_dir, f'id2ins_{scene_id}.json'), 'r') as f:\n",
    "            id2cls = json.load(f)\n",
    "        with open(os.path.join(id2part_dir, f'id2part_r{scene_id}.json'), 'r') as f:\n",
    "            id2part = json.load(f)\n",
    "\n",
    "        # Process unique classes and parts\n",
    "        for cls in set(id2cls.values()):\n",
    "            if cls not in cls_dict:\n",
    "                cls_dict[cls] = cls_index\n",
    "                cls_index += 1\n",
    "        for part in set(id2part.values()):\n",
    "            if part not in part_dict:\n",
    "                part_dict[part] = part_index\n",
    "                part_index += 1\n",
    "\n",
    "        # Read the point cloud\n",
    "        scene_ply = o3d.io.read_point_cloud(os.path.join(scene_dir, scene_id, f'points_{scene_id}.ply'))\n",
    "        points = np.asarray(scene_ply.points)\n",
    "\n",
    "        # Load the mask\n",
    "        masks = np.loadtxt(os.path.join(gt_instance_dir, f'mask_{scene_id}.txt'))\n",
    "\n",
    "        # Ensure masks have the same length as points\n",
    "        assert len(masks) == len(points), f\"Mismatch in length for scene {scene_id}\"\n",
    "\n",
    "        # Get unique labels\n",
    "        unique_labels = np.unique(masks)\n",
    "\n",
    "        # Prepare summary file\n",
    "        summary_file_path = os.path.join(scene_save_dir, f'{scene_id}_summary.txt')\n",
    "        with open(summary_file_path, 'w') as summary_file:\n",
    "            # Process each unique label\n",
    "            for label in unique_labels:\n",
    "                if label == 0:  # Assuming 0 is background or unlabeled\n",
    "                    continue\n",
    "\n",
    "                # Extract points for this label\n",
    "                label_mask = masks == label\n",
    "                label_points = points[label_mask]\n",
    "\n",
    "                # Save the mask for this label\n",
    "                mask_filename = f'{int(label):03d}.txt'\n",
    "                mask_filepath = os.path.join(pred_mask_dir, mask_filename)\n",
    "                np.savetxt(mask_filepath, label_mask.astype(int), fmt='%d')\n",
    "\n",
    "                # Get class information\n",
    "                class_name = id2cls.get(str(int(label)), \"unknown\")\n",
    "                class_index = cls_dict.get(class_name, -1)\n",
    "\n",
    "                # Calculate confidence (placeholder, you may want to implement your own logic)\n",
    "                confidence = 1.0\n",
    "\n",
    "                # Write to summary file\n",
    "                summary_file.write(f\"pred_mask/{mask_filename} {class_index} {confidence}\\n\")\n",
    "\n",
    "        print(f\"Processed scene {scene_id}\")\n",
    "\n",
    "    print(\"All scenes processed.\")\n",
    "    return cls_dict, part_dict\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_dir = '/home/wan/Datasets/Test_scene'\n",
    "    save_dir = 'part_scene_results'\n",
    "    cls_dict, part_dict = process_point_clouds(dataset_dir, save_dir)\n",
    "\n",
    "    # Optionally, save cls_dict and part_dict\n",
    "    with open('cls_dict.json', 'w') as f:\n",
    "        json.dump(cls_dict, f, indent=2)\n",
    "    with open('part_dict.json', 'w') as f:\n",
    "        json.dump(part_dict, f, indent=2)\n",
    "\n",
    "    print(\"Unique classes:\")\n",
    "    for cls, index in cls_dict.items():\n",
    "        print(f\"{index}: {cls}\")\n",
    "\n",
    "    print(\"\\nUnique parts:\")\n",
    "    for part, index in part_dict.items():\n",
    "        print(f\"{index}: {part}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
